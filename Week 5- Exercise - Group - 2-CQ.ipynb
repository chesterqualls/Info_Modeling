{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Exercise\n",
    "\n",
    "**Assignment**: This exercise will explore applications of machine learning. Specifically, your group will have to complete the following:\n",
    "  \n",
    "* Describe model fit\n",
    "* Describe applications for supervised learning\n",
    "* Describe applications for unsupervised learning\n",
    "* Hypothesize on potential cluster groupings\n",
    "* Comment on the future of machine learning\n",
    "\n",
    "\n",
    "For this exercise, you will have to complete all the tasks within this notebook, save the entire notebook, and then upload into the Week 5 Assignment for your group on BlackBoard. Save this notebook with a new name with the following format:\n",
    "\n",
    "**Week_5_Exercise_Group_group_number.ipynb**\n",
    "\n",
    "These in-class exercises are designed to allow you to explore Python with your group and **DO NOT** include step-by-step directions or answers that have only one possibility. Use your team and other resources to determine how best to complete them. Make sure before you turn in your notebook that it runs without errors and the requested output is visible in the notebook. If you go through multiple steps in your code, make sure all those steps are included so that we can evaluate your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 1\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "#### What is \"model fit\" and why is it important when interpreting output from models like those in supervised machine learning?\n",
    "> In simple terms \"model fit\" means finding the appropriate model to use, in this case, for Machine Learning (ML). Should  you use supervised or unsupervised ML, and how many clusters make sense?  Or maybe you don't want to see clusters at all because you aren't looking to group information but to see a trend, or a regression. \n",
    "\n",
    "> Picking the correct model is important when interpreting output primarily at the point you plan to take any action on your analysis.  Until then you are free to suppose whatever you like.  But once you must make a decision, the moodel must provide you correct information.  For example, let's say you select supervised ML, you pick the categories and train the system to identify the data based on your assumptions.  Those assumptions may not be good.  \n",
    "\n",
    "> In a previous lab we looked at a Natality Database from a GSOD website. We wanted to know about the impact of not only smoking but the number of cigarettes smoked by the mother, on the health of a newborn baby. The baby's health was to be determined from the Apgar Scores.  If we took the dataset and randomly select a subset we will use to \"train\" the system by creating categories(clusters) for number of cigarettes smoked (1,2,3,4,5,6,7,8,9,10+) and then ran the remainder of our data for results, would we come up with anything meaningful? This model could be a bad fit for multiple reasons. It could be looking at the wrong clusters, or it could be looking at the wrong filter. But there is no one correct model for every situation.  \n",
    "\n",
    "> The key for our purposes is that the right model is the one that helps us make the best decision.\n",
    "\n",
    "\n",
    "#### How might \"model fit\" and \"overfitting\" lead to inaccurate interpretations (use an example)?\n",
    "> As we mentioned above in the Lab where we proposed looking at cigarette usage as a determining factor in newborn health, clustering by each additional cigarette may not provide relavent information.  Too many clusters is an example of overfitting the model, which could lead to inaccurate interpretations. It may be better to group the data such as 2 or less, 3 to 6 and 7 or more. Looking at the difference between 2 and 3 cigarettes, and then comparing 3 to 4 may show us only minimal changes and we may assume there isn't a problem looking at each step in that way.  But when we look at them in groups we may see that less than 2 has little impact, but 3 to 6 is much worse.  We of course have to play with this a little.  Maybe less than 3 is okay but the real problem is the next 2 cigarettes when you are in the 4 to 6 range.  In other words you can't \"see the forest for the  trees\" may accurately describe the results you generate if your model is an overfit. Overfitting can result in poor predictive performance as it exagerates minor fluctuations in the data. The result accurately models the training data, but is not generally predictive beyond the training data.  \n",
    "\n",
    "> Some of the problems we come across are characterized in one of the readings we found... \n",
    "\n",
    "> \"The most common mistake beginners make when training statistical models is to evaluate the quality of the model on the same data used for fitting the model:  If you do this, you are doing it wrong!\n",
    "\n",
    "> The problem lies in the fact that some models can be subject to the overfitting issue: they can learn the training data by heart without generalizing. The symptoms are...\n",
    "\n",
    "> The predictive accurracy on the data used for training can be excellent (sometimes 100%)\n",
    "however, the models do little better than random prediction when facing new data that was not part of the training set. If you evaluate your model on your training data you won’t be able to tell whether your model is overfitting or not.\"\n",
    "\n",
    "Source: http://www.astroml.org/sklearn_tutorial/general_concepts.html  (section 2.6.1)\n",
    "\n",
    "*Also in the reading mentioned we found a picture that tells the story. Just as in the story of Goldilocks and the 3 Bears, one is too little, another is too big, but there is one that is just right.*\n",
    "\n",
    "![](https://sites.google.com/a/asu.edu/team2/graphics/OverfitExample.JPG \"Overfit Example\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 2\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "#### What are some examples from your work where supervised learning could be applied?\n",
    "> Let's consider our final project for Odin Coffee.  We plan to take cash register data, and overlay it with external data such as weather and events.  We also plan to overlay this with in-store data we will collect which for one thing will tell us how long people stay in our store, and if they are alone or with a group.  We may collect this information by using phone app data that our customers use.  We could also track this by getting info from our in-store high speed WiFi (a free service we provide for our customers). We would know how many people are currently connected, how many tables we have in the store and how long they stay connected.  This allows us to figure out a number of things about them.  We could also use some in-store sensors provided through a project from Intel which helps retail outlets gain more understanding our customer behavior.\n",
    "\n",
    "> So now we have a lot of data but what can we do with it?  In supervised learning we come at the data with some assumptions.  We may want to know what difference it makes if our customers are in the store for 5 minutes, 30 minutes, 1 hour or 2 hours?  Most likely we want to know how this affects their purchases.  \n",
    "\n",
    "> That's just one dimension of data, what if we want to add to that what the difference is if they are alone (studying perhaps), or a group. Does the size of the group sliced with the time make any difference?  Do a husband and wife sitting at a table and reading the newspaper drink more coffee than a student reading a textbook?  Or a group of ladies with their children in tow?  And we could add other dimensions as well such as how does the weather outside affect ay of these other variables?  \n",
    "\n",
    "> With those questions we can create clusters and train our database with historical information so that it can begin to recognize the types of groups we identified and the behaviors that are expected from these variables. This information can inform the behavior of our staff, so that they are ready for the most likely scenario.\n",
    "\n",
    "> We could look at a completely different set of variables related to frequency of visit by a guest, how often they come in groups or alone, and how that changes the length of time they stay and what their purchases are likely to be depending on the time of day.\n",
    "\n",
    "> And of course we could begin to try a few test and learn experiments to see if we can change the behavior in a positive way for both the customer and for Odin Coffee. \n",
    "\n",
    "#### What benefit would machine learning have over simple reports of frequency for the same data?\n",
    "> We can create reports for all the breakdowns we mention above, though it would be difficult to get them on one single report.  But we could.  We would sit down... most likely with a cup of coffee, and look over them.  But we are not likely to see the paterens, we won't be able to accurately guess what is going to happen.\n",
    "\n",
    "> In a small coffee store it is fairly easy for a barista to get to know the regulars.  They come into the store so often the barista may even know what they regularly order and start to make it as soon as they see them.  They probably know each other's names and maybe even more.  The barista may also know when that particular customer is likely to come into the store, and if they don't wonder what happened.  This is all information they can keep in their head and is similar to a simple report.\n",
    "\n",
    "> But what will happen when an unknown customer walks in the door?  Or that group of ladies with kids in tow?  What will happen if the customer who usually comes in by themselves to read a book while drinking a cup of coffee, but one day shows up with a friend, or stays for 2 hours rather than 30 minutes?  A simple report can't provide any ideas.  \n",
    "\n",
    "> This is where Machine Learning comes into play. The computer algorithm, based on the training \"labels\" provided (if supervised learning) can predict the next sequence of events.  It can suggest the outcome, and hopefully enrich the business decisions beyond what the standard report is capable of doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 3\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "#### How could unsupervised learning be used by the Pokémon Company to group users using Twitter data?\n",
    "> Pokemon Company could use twitter data to group user Pokemon participation enthusiasm based on their tweet activity. For example, using feature inputs such as Pokemon tweet frequency and positiveness you could use unsupervised machine learning to create groups. These groups could be monitored over time. \n",
    "> The purpose we have looked at for using unsupervised learning is to determine how to cluster or group the data into something meaningful.  We looked primarily at the <span style=\"background-color: #F0E68C\">K-Means method</span>.  Using K-Means Pokemon could cluster twitter data by 2 or more dimensions attempting to determine enthusiasm. Pokemon could create 2, 3, 4 or more clusters to determine low-medium-high levels of enthusiasm of  users. They could also use K-Means to cluster users by age perhaps.  Muhammad in our group has a young son who is excited by the Pokemon universe, collecting cards as some of us did with baseball cards, and playing the games.  Chester's son is now 19, and although he began playing in the Pokemon Universe at the age of Muhammad's son, he is still playing.  He still buys games, consoles and such.  He also has all the old devices, Nintendo 64, Game Cube, Wii-U, and multle generations of handheld devices.  The way these two boys approach the Pokemon, and their individual ability to make decisions (Chester has no idea what his son buys any more) are differences the Pokemon company would be interested in.  \n",
    "\n",
    "> Pokemon could also use models other than K-Means such as the <span style=\"background-color: #F0E68C\">Hidden Markov Model</span> which goes beyond clustering of Means/Averages and considers probability of connections to other activity.  They could also use <span style=\"background-color: #F0E68C\">Hierarchical clustering</span> to make a different connection between people in an order of dominant features or precedence for example.  These learning methods could be used in interesting ways as well.  \n",
    "\n",
    "![Pika-Pika](https://sites.google.com/a/asu.edu/team2/graphics/pikachu.png \"Gotta catch 'em all!!!\")\n",
    "\n",
    "#### What value would user groups have for the company overall and functions like marketing?\n",
    "> Marketing could use trends in the groups to evaluate the impact of specific marketing campaigns. As we mentioned above both Muhammad and Chester have sons that like Pokemon. But their buying decisions are different   Muhammad still has most of the control over what his son buys (unless his wife buys it).  But Chester has no say in the matter, both his wife and his son could be buying. (Chester has obviously lost all control)  To Pokemon this is important to know.  Who is making the real decisions? Does the one with the twitter account have their own bank account and credit card, or do they depend on someone else?  The motivations or desires for features of an 8 year old boy are also different from those of a 19 year old Freshman in college.  One of the things they do have in common of course are great and intelligent fathers... just sayin'.  Pokemon will likely have different marketing campaigns for each. Muhammad's son may be more likely to watch a new Saturday cartoon so the marketing campaign directed at him would be during a commercial.  Chester's son may be more likely to watch a You-Tube Channel so the marketing campaign for him would be there (or these could be reversed, who knows?)\n",
    "\n",
    "> And the more Pokemon knows the better they can market.  If Chester's son buys his Math textbook for Kindle the Ad campaign could be displayed on the device where he reads his book.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 4\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "#### Without running any analyses, what types of useful user groups do you think the Pokémon Company might find if they were to run a machine learning clustering analysis on Twitter data?\n",
    "\n",
    "> We mentioned examples of these user groups in answering the above questions.  But to recap...\n",
    "\n",
    "> The unsupervised machine learning described in response 3 could result in 3 grouping of Pokemon enthusiasm: Low, Moderate and High. This machine learning model could be run prior to and after a marketing campaign to determine its effectiveness.\n",
    "\n",
    "> The unsupervised machine learning could also help determine buying authority and make groups accorind to different levels of financial decision making. This information could alter the marketing campaign, it's features, where it is placed, and what they promote in the campaign.  \n",
    "\n",
    "> As we saw with the Twilight series of books (a romantic Vampire saga), with Team Jacob vs. Team Edward, Pokemon may determine groups of people who prefer one character over another.  This could not only inform marketing but it could also inform cartoons and battle activity during game play.  \n",
    "\n",
    "![Pika-Pika](https://sites.google.com/a/asu.edu/team2/graphics/Pxywikibattle3.png \"I choose you Pikachu.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 5\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "***Artificial intelligence and the general idea of machine learning is a field that has been around since 1955.*** \n",
    "\n",
    "#### Why do you think ML has attracted so much more attention and investment in the past 10 years compared to the previous 50?\n",
    "\n",
    "> Moore's Law...  Finally, delivered the computing, storage and communications performance required to support the needs of machine learning. This in a nutshell is why the popularity of machine learning has grown.  \n",
    "\n",
    "> Because Moore's Law has made Machine Learning more accessible the standard limitations of business intelligence can be overcome as well.  Standard business intellegence has been fantastic at helping inform human decision. It has show us what we can not see otherwise, but the decision is still made by a human.  \n",
    "\n",
    "> Machine learning is moving business intellegence from predictive to prescriptive.  The machine can go beyond informing the decision to making the decision and taking actions.  Humans need only to look for exceptions to the rules.  It turns out there a many decisions that are unnecessary for humans to make, but we still want certain things to happen... the right things.  Whether we train the data or not the machine can look at the data and take action far faster than a human.  For now we still have a few advantages however.\n",
    "\n",
    "> And due to the improvements in processing speed, data storage, and universal distribution machine learning allows for deeper understanding of the data.  In thinking of examples for these questions it is often easy to look at the x-axis and compare to the y-axis, and see the results.  This 2-D thinking is easy.  We can fairly easily go beyond this as we did during Sean's demonstration on plotting the results of machine learning and consider the 3rd dimension or the z-axis.  But past that it becomes more difficult for the human mind to comprehend.  Computers however can go there.  We can throw 10 dimensions at them and they don't mind.  That's where a huge depth of insight comes.  \n",
    "\n",
    "> In some of the modeling we have done in other classes such as for risk analysis we worked with formulas that we used for only a few dimensions but apparently are capable of many more.  So machine learning will help us in dealing with risk propositions.  And as we learned in just 2 or 3 dimensions you can mitigate risk by understanding from a deeper place.  But now we are beginning to answer for the next question and we should probably answer there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 6\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "#### How important do you think machine learning is for the future of data science and analytics (support your answer with examples and data as appropriate)?\n",
    "\n",
    "> Very. To put some of what we answered in Question #5 in a different way... \n",
    "\n",
    "> Unstructured data does not lend itself well to traditional statistical analysis. The volume, velocity and variety of data being generated today by the internet of things lends itself well to the flexibile analytical capability provided by machine learning. Consider the amount of video data being generated by the world's security cameras. Maching learning is well suited to sift through it to identify a specific person or activity. Another example, would be to use the diverse data on social media (i.e. text, pictures, emoticons, audio, video) to predict the potential for unrest in a particular part of the world.\n",
    "\n",
    "> As we have mentioned, for our purposes we hope to inform, assist, or replace decision making by humans with the techniques we are learning both in traditional business intelligence and in machine learning.  Better decisions are the goal.  But there is another even perhaps deeper goal that we touched on in the last question.\n",
    "\n",
    "> Risk!!!  We want to make decisions, but we don't want to pay the penalties for decisions gone wrong.  We want the right decision to be made.  We want to reduce the risk of the decisions we <span style=\"background-color: #F0E68C\">MUST </span> make?  As we pointed out we have to look at the decisions from every angle (multiple dimensions if you will) to reduce or maybe even eliminate the risk involved.  Like a chess game we need to be thinking 10 or more moves ahead.  Probably the best hope of that happening is machine learning.  With machine learning we can take steps which considered on their own seem risky, but in truth are not.  \n",
    "\n",
    "> Feed the Machine. The data coming too fast for humans to decipher is what will drive the future.  We humans learn slowly by comparison.  Some lessons take years, some only days, and a few hours, but a computer can create models and learn by the thousands in the time that we can learn from two.  From the moment we fashioned the crudest of tools from rock or bone mankind has been looking for ways to make their work easier. Machine learning is the next phase in that evolution.  We experienced the stone age, the iron age, the bronze age which are periods of time where \"technology\" advanced our abilities.  Today, due to computers we are moving through \"Ages\" much more quickly, advancing from one \\*Eureka\\* moment to the next.  Machine learning will assis these new epochs in advancement.\n",
    "\n",
    "> Some ideas of advancement are in [this article](http://venturebeat.com/2015/02/28/how-machine-learning-will-fuel-huge-innovation-over-the-next-5-years/). Because healthcare is such a hot topic that idea stands out. As the article mentions many people are wearing IoT devices such as Fitbit.  This is likely to happen even more frequently and the sensors will collect even more data than they currently do.  You doctor could monitor you on their real-time dashboard.  We may see healthcare companies develop new services in this area.  But that simple idea is somewhat limited.  If you could combine all the sensors worn by people along with existing medical databases and research we could witness a whole new level of healthcare as a result of machine learning.  This of course opens a whole new world of problems as well.  And those too are part of the future of machine learning.  What decisions will be made by your health insurance company if you continue to behave in a way you should not?  Will your insurance have exclusions to control their expenses?  With all the knowledge accumulated people could become conserned (and rightly so) about what corporate, government or even individuals will do with the knowledge they recieve.  So along with advancement will be new challenges.\n",
    "\n",
    "> Finally, machines will not replace humans.  This has been the worry about technology advances throughout history.  It is natural for us to worry about the unknown.  But just like previous advancements, humans will figure out how to best utlize what we have created.  Anyway the future of machine learning is exciting, you can tell we think so."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

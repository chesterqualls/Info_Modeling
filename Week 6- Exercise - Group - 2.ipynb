{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Exercise\n",
    "\n",
    "**Assignment**: This exercise will explore MapReduce and Apache Spark. Specifically, your group will have to complete the following:\n",
    "  \n",
    "* Evaluate IPython Parallel versus MapReduce\n",
    "* Use IPython Parallel to build a numeric example of the general map and reduce pattern \n",
    "\n",
    "\n",
    "For this exercise, you will have to complete all the tasks within this notebook, save the entire notebook, and then upload into the Week 6 Assignment for your group on BlackBoard. Save this notebook with a new name with the following format:\n",
    "\n",
    "**Week_6_Exercise_Group_group_number.ipynb**\n",
    "\n",
    "These in-class exercises are designed to allow you to explore Python with your group and **DO NOT** include step-by-step directions or answers that have only one possibility. Use your team and other resources to determine how best to complete them. Make sure before you turn in your notebook that it runs without errors and the requested output is visible in the notebook. If you go through multiple steps in your code, make sure all those steps are included so that we can evaluate your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce\n",
    "\n",
    "While the general map and reduce pattern we used in this week's notebook is different from Google's initial description of MapReduce which evolved into Apache Hadoop, the general patterns have many similarities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 1\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "#### Drawing from sources on the Internet as required, what are the benefits of Hadoop and MapReduce compared to traditional database and analytics technologies?\n",
    "> * MapReduce/Hadoop can deal with massive data sets which the traditional database can't even touch.\n",
    "* Don't have to pre-process the data to use it, such as developing a star schema for a datamart. Structured vs. Unstructured.\n",
    "* Hadoop more easily scalable.\n",
    "* Hadoop is cheaper, due to it's use of low-cost commodity servers in volume rather than expensive specialty servers with pricey storage solutions. Also due to fewer license costs... typically (may become less true because of the pressure the open source community has put on traditional software companies. Open source has become competitive... and a better overall value.)\n",
    "* Map/Reduce splits up a task rather than having to run through information sequentially as traditional analytics technologies would. Traditional analytics don't typically run processes in parallel. \n",
    "* You can tap into more types of data with this.\n",
    "* Typically faster on larger data sets.\n",
    "* In a batch process, Hadoop provides a faster recovery from failures than traditional databases. This is because the traditional database has to start over, the Hadoop process picks up at the point of failure.  This could save hours.\n",
    "\n",
    "\n",
    "> https://www.quora.com/What-are-the-advantages-of-Hadoop-over-distributed-RDBMS\n",
    "\n",
    "> * RDBMS systems use indexing to speed up processing, but almost every database system like this we have come across have \"repair\" functions, this is not typically because the data is messed up, but the index.  The repair system re-builds the index so that the systems work again. This is not as big a problem as it once was but it is still an issue that Hadoop doesn't really experience because it doesn't rely on indexes, or they are created on the fly.\n",
    "\n",
    "\n",
    "> One of the biggest benefits of Hadoop in particular is that it was a game changer for the open source community. At least it seems to have been. In the past, open source software was a reaction to what was going on in the market, at least from the perception of the average personal computer consumer.  Hopefully our logic is sound here.  Open source does have a good beginning though.  Going back to the early days of computing there were mainframes, the workstations were referred to as terminals or \"dumb terminals\" at times, no real processing happened there.  The processing was at the central computer which was controlled by companies such as IBM, Digital Equipment Corporation and such.  Many of the operating systems they used were based on Unix.  In a sense Unix was open source, but each company's version of it was controlled by them.  When the personal computer era began in the 80's Microsoft bought and further developed PC-DOS for IBM (and in a stroke of genius kept the rights to develop MS-DOS themselves).  Apple created their own OS as well.  And the open source community responded with a derivation of Unix called Linus (a mixture of Unix and Linus the name of it's founder). Some, such as RedHat mentioned in class tried to legitimize Linux for the business community at large by standing behind their product with support and somewhat traditional licensing.  \n",
    "\n",
    "> Quickly we needed to be able to do something with these new computers so applications were developed for the work space.  Lotus 1-2-3 was the king in spreadsheets.  WordStar and WordPerfect were battling for Word Processing. Microsoft, which was a minor player in this space came in with the Office Suite.  They had Word and Excel before this, but those were not major players (until Microsoft brilliantly combined them together and sold the whole suite for far less than the cost of Lotus alone).  \n",
    "\n",
    "> The Open Source community responded with Open Office, and later refined with Libre Office. And of course, there was the development of the Local Area Network as a replacement to early networking technology.  Novell had dominance, Microsoft again came in from behind with a cheaper solution originally with Windows NT Server, and subsequent developments.  Unix tried to keep up, but Open Source didn't keep up until the Internet began to take off and names like Linux (mentioned before) and Apache developed solutions.\n",
    "\n",
    "> **What's the point of the history lesson?**\n",
    "\n",
    "> Open source often reacted to what was already going on, or did not provide the best solution in the particular space.  \n",
    "\n",
    "> Not completely positive about this, but Hadoop was a key factor in changing all of this. Hadoop though taking work done by Google with MapReduce, pioneered the effort.  Perhaps MapReduce was the original explorer, but Hadoop was the one that brought it to the people.  This was not a reaction to commercially available software, this was new territory. The traditional licensing companies haven't been able to move in and take over because Hadoop hit the target.  Hadoop may well be the \"killer-app\" that also made Apache legitimate in the business world.  This is the premier solution, not a reaction.  And we would argue that it is not only bringing Apache along with it, but perhaps all open source as well.  That seems like a big benefit worth mentioning in addition to the list we already provided.   \n",
    "\n",
    "\n",
    "#### What are the downsides of Hadoop and MapReduce?\n",
    "> * Typical RDBMS can be better optimized for those questions which are asked over and over again.\n",
    "* Hadoop may not have the advantages of RDBMS with transaction data such as accounting info.  Some information is structured by design... and should be.  Try to hand a shoebox full of video and text files to an IRS auditor.\n",
    "> https://www.quora.com/What-are-the-advantages-of-Hadoop-over-distributed-RDBMS\n",
    "\n",
    "> * Because of the way Hadoop is introduced into a company, it may or may not have good data governance in place as most RDBMS systems do.  https://www.quora.com/How-can-my-company-benefit-from-using-Hadoop-over-traditional-data-warehouses\n",
    "* Many companies do not have access to the expertise required to use Hadoop and MapReduce effectively.\n",
    "* The management and culture of many companies is not ready to make use of Hadoop and MapReduce. They don't understand  how it works, what is possible and how to plan a strategy to use its capabilities.\n",
    "* While everyone is reading and talking about big data, many companies are not able to see the business value it could deliver for them.\n",
    "* Even after overcoming the challenges described above, once a company establishes value using Hadoop and MapReduce it, can often be duplicated by competitors if it only relies on publicly available data. Effectively including internal data that the competition does not have access to is one way to stop this. The other way, is to keep innovating, staying one or more steps ahead of the competition with innovative use of Hadoop and MapReduce.\n",
    "\n",
    "> As mentioned above, MapReduce/Hadoop filled a gap in the business world of data opening new territory and enabling the concept of big data, but for all that it got right it's biggest downside is that it does not do everything.  Now that the door is open and the flood of data is coming in, data administrators need tools to manage this brave new world.  Hadoop doesn't provide it. You have to go to 3rd party sources to make these things happen.  That is somewhat okay.  Hadoop may have legitimized open source development, but even in the world of licenses software the 3rd party developers do not have the same focus as the \"main product\" they are developing for.  The solutions can range from good to bad, and there isn't a great way to find out which it is until you play with it.  The 3rd party add one may not get the same attention that Hadoop is getting from the open source community.  Again, in addition to the list we provided this is a downside to MapReduce/Hadoop. It will not slow down the adoption of Hadoop most likely, but it will create challenges until resolved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 2\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "#### Again, drawing from information on the Internet as needed, how would you compare Apache Spark to Apache Hadoop in terms of potential value to a firm that has yet to adopt \"big data\" technologies?\n",
    "> * Spark runs in memory, Hadoop from drives (but of course processing takes place in memory.  So Spark is good when you have to pass over data multiple times (such as iterations in machine learning) this is enabled by its interactive shell, but if it is a one pass process Hadoop may have benefits (such as ETL processes), or be just as good without investment in more expensive memory rather than cheap drives.\n",
    "* Spark is great if the data fits into the available memory, but fails if it does not.\n",
    "* Spark has some nifty tools and is interactive, Hadoop is more difficult to program.  There are tools you can add to Hadoop to make it easier such as Pig (which helps with programming) and Hive (for SQL on top of Hadoop). There are people working on the interactive tools for Hadoop.\n",
    "* Both Spark and Hadoop have somewhat similar hardware requirements, but the difference is for Spark you need lots of, memory, and for Hadoop you need lots of drive space.  Drive space is still cheaper than memory... at least for now.\n",
    "* Spark is more one stop shopping, real-time or batch processing, reporting, visualizing data and such.  Hadoop utilizes 3rd party products for most of this.\n",
    "* The vast majority of open source contribution  has shifted to Spark.\n",
    "* Because Hadoop has been around longer it is more robust in security features than Spark.\n",
    "\n",
    "> https://www.xplenty.com/blog/2014/11/apache-spark-vs-hadoop-mapreduce/\n",
    "\n",
    "> https://www.quora.com/What-are-use-cases-for-Spark-vs-Hadoop\n",
    "\n",
    "> ### Bottom Line: Why not both?\n",
    "\n",
    "> Some of this commentary influenced by [this article](http://siliconangle.com/blog/2015/02/05/apache-spark-hadoop-friend-or-foe/).\n",
    "\n",
    "> Hadoop involves two separate parts, the processing engine and the data storage HDFS (Hadoop Distributed File System).  Both parts can be replaced by better solutions.  Apache Spark is a replacement only for the processing engine, and a fine replacement at that.  But Apache doesn't have its own data storage. It is independent of that storage.  I can run on top of HDFS or Amazon Web Services (AWS) for example.  \n",
    "\n",
    "> Now you could look at this and be tempted to say that that Hadoop is no longer necessary.  It is a relic of times past.  Which in today's computing environment was a couple years ago, not a couple decades ago as in computing past.  But only merely has to look back at computing history to know you should not rule out Hadoop.  As far as we know there are still mainframe computers, maintained and manufactured. Do we still need them? There apparently seems to be a market. We could wonder why IBM still exists as a company, but they do. They may no longer lead the entire industry as they once did, but they are still a strong company for now.  \n",
    "\n",
    "> We find a way to keep using the technologies we have created. So at least for the foreseeable future Hadoop will continue to be a force. It was first to dominate in its market. If anything Spark is the product to worry about. It is hot, but will it fizzle? Whether we call the next evolution Spark or not the capabilities it explores, which are mentioned above, will be relevant for some time yet. Spark has brought the innovation of Hadoop into the space of a real-time solution. We do so hate waiting for computing to happen.  \n",
    "\n",
    "> So right now both Hadoop and Spark have a place in your big data solution toolbox.  You won't try to do things with Spark that Hadoop does better (would be somewhat foolish for Spark to come up with it's own storage solution for example).  And it could be painful to try to do Spark type stuff with Hadoop and seven 3rd party apps. So use both. \n",
    "\n",
    "> *And if you happen to still have an IBM mainframe around, we won't judge you.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Response 3\n",
    "(Enter Your Response in This Cell)\n",
    "\n",
    "#### In the past, many firms relied on a single technology vendor for their data warehouse needs (Teradata, Microsoft, Oracle, etc.) In the era of \"big data\", what are the risks of relying on a single vendor for your analytics infrastructure?\n",
    "> * Less flexibility in providing solutions for making business decisions.\n",
    "* Less negotiating power and ability to challenge your vendors based on the features offered by your other solution providers.\n",
    "* Dependence on the capabilities and business continuity plan of only one vendor.\n",
    "* Spreading some of your risk (other than security related).\n",
    "* Missing out on advances made, if your vendor does not include it. This is because innovation happens much faster in the open source ecosystem.  \n",
    "\n",
    "> Beyond the list above, this question may need to be answered in light of the market maturity of data warehouse solutions. Consider this article [Medical Imaging Options: No Single Vendor Will Do](http://www.informationweek.com/interoperability/medical-imaging-options-no-single-vendor-will-do/d/d-id/1105523) about the issue healthcare facilities have in storage of the variety of images they need for patients. Let's step sideways for a moment and bring up a condition that we talked about in our Enterprise Systems class last quarter.  We talked about how many mid to large size had relied on multiple vendors for their systems.  Perhaps one for core financials, another for customer relationship management (CRM) and a third for manufacturing processes, or estimating, or whatever.  Some of us in the group recall the early days of financial systems. It was a big step to get just your financials off of the paper ledgers and into a computer.  Many people picked a vendor such as Solomon, Great Plains, Real World, etc. (Chester sold the three mentioned in his early career).  But after getting the financials under control, many people wanted to get more of the daily operations of their company onto the computer as well.  Often the accounting programs didn't accommodate this so people would look to 3rd party add on's or completely separate companies. It was a natural process wanting more of their business to fall under the computer umbrella. Next phase was for these vendors to open up their systems to allow for better synchronization of the systems with each other (customizations, which we learned are bad, but were essential to move forward in those times). And now that the markets have matured more, smaller companies have been bought or dissolved, we see people trying to get rid of customizations which cause difficulties as every update comes down.  \n",
    "\n",
    "> What's the connection?  Big data is moving the world of data warehousing along more quickly, but a similar technology cycle seems to be at play. When first taking off, you would pick a vendor for your warehouse or simply go with the only vendor that focused on your market.  As the article mentions medical facilities went with a solution for imaging, but now that their needs are growing and different types of images need to be stored they are having to consider multiple vendors for some of the reasons mentioned above. As quoted in the first paragraph \" they're realizing that no one vendor can provide all the technology to support such a strategy\".  Just as it was in the previous days of Enterprise Systems there really is no choice.  One vendor probably can't keep up with the multi-dimensional needs of your big data solutions.  Diversification is likely the only option.\n",
    "\n",
    "> However, considering the cycle, it is likely that at some point in the near future the vendors will merge, purchase new start ups and mature what they offer and a healthcare company will be able to store all their imaging needs with a single provider. Asking this question 5 years from now may provide a different list of answers than those we gave here.\n",
    "\n",
    "**Sorry for all the history in this week's submission, some of us lived it and would like to think it's still important**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
